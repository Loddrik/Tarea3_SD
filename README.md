# **Sistemas Distribuidos:  Tarea 3**

>
>Integrantes:
>
> - Brian Castro
> - RubÃ©n Hermosilla
>

## **Instrucciones de uso**

1. Clonar repositorio â¬‡ï¸
>
> ```bash
>    https://github.com/Loddrik/Tarea3_SD.git
>    ```
>

2. Ejecutar docker compose ðŸ
>
>```bash
>    docker-compose up --build
>    ```
>
3. Esperar a que los contenedores estÃ©n listos, esto toma tiempo asÃ­ que tome asiento y traiga sus palomitas ðŸ¿ â°.

4. Una vez cargado (observar en la consola), podemos hacer uso de las rutas solicitdas. Un ejemplo de uso es el siguiente:

>
> 1. Creamos un paciente en la siguiente ruta:
>
>```bash
>    http://localhost:3000/create [POST]
>    ```
>
> con los parÃ¡metros:
>
>```json
>    {
>        "rut":"20330013-1",
>        "nombre":"Brian",
>        "apellido":"Castro",
>        "fecha_nacimiento":"222"
>        "email":"brian.castro@mail.udp.cl",
>    }
>    ```
>
> Donde la Response serÃ¡ el identificador de la receta.
>
> 2. Editamos la receta asignada al paciente en la ruta:
>
>```bash
>    http://localhost:3000/edit [POST]
>    ```
>
> con los parÃ¡metros:
>
>```json
>    {
>    "id":"id de la receta que salga jeje",
>    "comentario": "Debido a la inflamaciÃ³n del recto y ano, se recomienda una buena lavada de poto.",
>    "farmacos":"Supositorios",
>    "doctor": "NicolÃ¡s Hidalgo"
>   }
>    ```
>
> 3.Verificar cambios!
>
>```bash
>    http://localhost:3000/getRecipes [GET]
>    ```
>
> 4. Podemos de igual manera eliminar la receta
>
>```bash
>    http://localhost:3000/delete [POST]
>    ```
>
> con los siguientes parÃ¡metros:
>
>```json
>    {
>       "id": "id que le aparezca al pvto del brian :v"
>    }
> 
>    ```
>
> 5. Usamos una vez mÃ¡s getRecipes para verificar la eliminaciÃ³n de la receta.
>

___

## **Preguntas planteadas**

1. Explique la arquitectura que Cassandra maneja. Cuando se crea el clÃºster Â¿CÃ³mo los nodos se conectan?
Â¿QuÃ© ocurre cuando un cliente realiza una peticiÃ³n a uno de los nodos? Â¿QuÃ© ocurre cuando uno de los nodos se desconecta?
Â¿La red generada entre los nodos siempre es eficiente? Â¿Existe balanceo de carga?

>
> Cassandra funciona con un equema distribuido peer-to-peer,
> en donde cada peer se conecta
> con otro mediante el protocolo Gossip,
> el cual permite entre miembros del anillo, "contarse
> chismes" para mantenerse informados continuamente.
>
> Como el esquema es descentralizado, cada
> nodo tiene el mismo peso e importancia que el resto.
> AdemÃ¡s como se dijo anteriormente, la
> forma que representa la arquitrectura implementada
> en Cassandra es de tipo Anillo, por lo que
> existe una sola vÃ­a continua para la comunicaciÃ³n,
> permitiendo aumentar la cantidad de lectutas
> distribuyendo la informaciÃ³n entre peers.
>
> Si le llega una peticiÃ³n a cualquiera de nustros
> peers, dicho peer debe de direccionar la peticiÃ³n
> al peer correspondiente. Luego, se escribe el log
> de la peticiÃ³n en una estructura llamada Mem Table,
> la cual funciona como respaldo en caso de que el nodo,
> caiga. Una vez escrita en la Memoria, se utiliza la SSTable,
> quien se encarga de escribir los datos desde la memoria (logs
> ordenados), hacia el disco.
>
> Cuando un nodo desea desconectarse, avisa a sus pares
> mediante Gossip, de tal forma que se aplique una estrategia
> como RPS (Replica Placement Strategy) o Snitch para repartir las
> consultas o replicar el nodo caÃ­do mediante la MemTable.
>
> Si hablamos de la red generada por Cassandra, podemos decir que
> es eficiente hasta cierto punto, dado que Cassandra en sÃ­ estÃ¡ hecho
> para procesar una inmensa cantidad de datos, por lo que es necesario
> manetener MemTables de gran tamaÃ±o. Ã‰sto Ãºltimo se traduce a que,
> es necesario tener una alta cantidad de memoria a medida que mÃ¡s nodos
> y/o mÃ¡s informaciÃ³n se requeira almacenar (y cuÃ¡nto tiempo). Por otro lado,
> se sabe que P2P es una arquitectura en la que si no se implementan ni
> formailizan procedimientos que aumenten el rendimiento como DHTÂ´S ,
> se pierde mucho tiempo accediendo a cada nodo, uno en uno.
>
> Finalmente, el balanceo de Carga que utiliza Cassandra es RandomPartitioner
> el cual distribuye las peticiones de manera aleatoria.
>

2. Cassandra posee principalmente dos estrategias para mantener reduncancia
en la replicaciÃ³n de datos. Â¿CuÃ¡les son estos? Â¿CuÃ¡l es la ventaja de uno sobre otro?
Â¿CuÃ¡l utilizarÃ­a usted para el caso actual y por quÃ©? Justifique apropiadamente su respuesta.

>
> Para mantener la redundancia de datos, Cassandra mantiene dos mecanismos.
> El primero es NetworkTopologyStrategy, la cual genera resÃºmenes (hash) para calcular
> un Merkle (Ãrbol binario).
>
> El segundo es SimpleStrategy, el cual coloca rÃ©plicas en peers posteriores, en direcciÃ³n
> del anillo.
>
> Es obvio y simple de ver en el nombre de estas estrategias que la primera
> es utilzada para redes mÃ¡s grandes, en donde se permite el almacenamiento
> de mÃºltiples copias de datos en distintos centros o datacenters.
>
> Para el caso actual se utiliza sÃ³lo un datacenter que contiene los 3 nodos que
> se piden en el enunciado, por lo que el mecanismo implementado o que mejor se adapta
> es el SimpleStrategy dada la topologÃ­a de tipo anillo que se forma.
>

3. Teniendo en cuenta el contexto del problema Â¿Usted cree que la solucipÃ³n propuesta
es la correcta? Â¿QuÃ© ocurre cuando se quiere escalar la soluciÃ³n? Â¿QuÃ© mejoras implementarÃ­a?
Oriente su respuesta hacia el Sharding y comente una estrategia que pidrÃ­a seguir para ordenar
los datos.
>
>
>
