# **Sistemas Distribuidos:  Tarea 3**

>
>Integrantes:
>
> - Brian Castro
> - RubÃ©n Hermosilla
>

## **Instrucciones de uso**

1. Clonar repositorio â¬‡ï¸
>
> ```bash
>    https://github.com/Loddrik/Tarea3_SD.git
>    ```
>

2. Ejecutar docker compose ðŸ
>
>```bash
>    docker-compose up --build
>    ```
>
3. Esperar a que los contenedores estÃ©n listos, esto toma tiempo asÃ­ que tome asiento y traiga sus palomitas ðŸ¿ â°.

4. Una vez cargado (observar en la consola), podemos hacer uso de las rutas solicitadas. Un ejemplo de uso es el siguiente:

>
> 1. Creamos un paciente en la siguiente ruta:
>
>```bash
>    http://localhost:3000/create [POST]
>    ```
>
> con los parÃ¡metros:
>
>```json
>    {
>        "rut":"20330013-1",
>        "nombre":"Brian",
>        "apellido":"Castro",
>        "fecha_nacimiento":"222"
>        "email":"brian.castro@mail.udp.cl",
>    }
>    ```
>
> Donde la Response serÃ¡ el identificador de la receta.
>
> 2. Editamos la receta asignada al paciente en la ruta:
>
>```bash
>    http://localhost:3000/edit [POST]
>    ```
>
> con los parÃ¡metros(el id cambia para cada objeto que se agrega, este solamente es un caso de uso real):
>
>```json
>    {
>    "id":"86537ae7-1e60-433d-a4ab-864a5664bf94",
>    "comentario": "Debido a la inflamaciÃ³n se receta un antinflamatorio xd.",
>    "farmacos":"Ibuprofeno",
>    "doctor": "NicolÃ¡s Hidalgo"
>   }
>    ```
>
> 3.Verificar cambios!
>
>```bash
>    http://localhost:3000/getRecipes [GET]
>    ```
>
> 4. Podemos de igual manera eliminar la receta
>
>```bash
>    http://localhost:3000/delete [POST]
>    ```
>
> con los siguientes parÃ¡metros:
>
>```json
>    {
>       "id": "86537ae7-1e60-433d-a4ab-864a5664bf94"
>    }
> 
>    ```
>
> 5. Usamos una vez mÃ¡s getRecipes para verificar la eliminaciÃ³n de la receta.
>

___

## **Preguntas planteadas**

1. Explique la arquitectura que Cassandra maneja. Cuando se crea el clÃºster Â¿CÃ³mo los nodos se conectan?
Â¿QuÃ© ocurre cuando un cliente realiza una peticiÃ³n a uno de los nodos? Â¿QuÃ© ocurre cuando uno de los nodos se desconecta?
Â¿La red generada entre los nodos siempre es eficiente? Â¿Existe balanceo de carga?

>
> Cassandra funciona con un equema distribuido peer-to-peer,
> en donde cada peer se conecta
> con otro mediante el protocolo Gossip,
> el cual permite entre miembros del anillo, "contarse
> chismes" para mantenerse informados continuamente.
>
> Como el esquema es descentralizado, cada
> nodo tiene el mismo peso e importancia que el resto.
> AdemÃ¡s como se dijo anteriormente, la
> forma que representa la arquitrectura implementada
> en Cassandra es de tipo Anillo, por lo que
> existe una sola vÃ­a continua para la comunicaciÃ³n,
> permitiendo aumentar la cantidad de lectutas
> distribuyendo la informaciÃ³n entre peers.
>
> Si le llega una peticiÃ³n a cualquiera de nustros
> peers, dicho peer debe de direccionar la peticiÃ³n
> al peer correspondiente. Luego, se escribe el log
> de la peticiÃ³n en una estructura llamada Mem Table,
> la cual funciona como respaldo en caso de que el nodo,
> caiga. Una vez escrita en la Memoria, se utiliza la SSTable,
> quien se encarga de escribir los datos desde la memoria (logs
> ordenados), hacia el disco.
>
> Cuando un nodo desea desconectarse, avisa a sus pares
> mediante Gossip, de tal forma que se aplique una estrategia
> como RPS (Replica Placement Strategy) o Snitch para repartir las
> consultas o replicar el nodo caÃ­do mediante la MemTable.
>
> Si hablamos de la red generada por Cassandra, podemos decir que
> es eficiente hasta cierto punto, dado que Cassandra en sÃ­ estÃ¡ hecho
> para procesar una inmensa cantidad de datos, por lo que es necesario
> manetener MemTables de gran tamaÃ±o. Ã‰sto Ãºltimo se traduce a que,
> es necesario tener una alta cantidad de memoria a medida que mÃ¡s nodos
> y/o mÃ¡s informaciÃ³n se requeira almacenar (y cuÃ¡nto tiempo). Por otro lado,
> se sabe que P2P es una arquitectura en la que si no se implementan ni
> formailizan procedimientos que aumenten el rendimiento como DHTÂ´S ,
> se pierde mucho tiempo accediendo a cada nodo, uno en uno.
>
> Finalmente, el balanceo de Carga que utiliza Cassandra es RandomPartitioner
> el cual distribuye las peticiones de manera aleatoria.
>

2. Cassandra posee principalmente dos estrategias para mantener reduncancia
en la replicaciÃ³n de datos. Â¿CuÃ¡les son estos? Â¿CuÃ¡l es la ventaja de uno sobre otro?
Â¿CuÃ¡l utilizarÃ­a usted para el caso actual y por quÃ©? Justifique apropiadamente su respuesta.

>
> Para mantener la redundancia de datos, Cassandra mantiene dos mecanismos.
> El primero es NetworkTopologyStrategy, la cual genera resÃºmenes (hash) para calcular
> un Merkle (Ãrbol binario).
>
> El segundo es SimpleStrategy, el cual coloca rÃ©plicas en peers posteriores, en direcciÃ³n
> del anillo.
>
> Es obvio y simple de ver en el nombre de estas estrategias que la primera
> es utilzada para redes mÃ¡s grandes, en donde se permite el almacenamiento
> de mÃºltiples copias de datos en distintos centros o datacenters.
>
> Para el caso actual se utiliza sÃ³lo un datacenter que contiene los 3 nodos que
> se piden en el enunciado, por lo que el mecanismo implementado o que mejor se adapta
> es el SimpleStrategy dada la topologÃ­a de tipo anillo que se forma.
>

3. Teniendo en cuenta el contexto del problema Â¿Usted cree que la solucipÃ³n propuesta
es la correcta? Â¿QuÃ© ocurre cuando se quiere escalar la soluciÃ³n? Â¿QuÃ© mejoras implementarÃ­a?
Oriente su respuesta hacia el Sharding y comente una estrategia que pidrÃ­a seguir para ordenar
los datos.

>
>Como sabemos, el sharding es una forma de segmentar los datos de una base de datos de forma horizontal, es decir, partir la base de datos principal en varias en bases de datos mÃ¡s pequeÃ±as y repartiendo la informaciÃ³n. De esta forma lo que se consigue es una particiÃ³n de datos en diferentes bases que tengan cierta homogeneidad, para conseguir una escalabilidad mucho mÃ¡s rÃ¡pida.
>
>En Cassandra, la distribuciÃ³n y la replicaciÃ³n de datos van juntas. Los datos se organizan por tabla y se identifican mediante una clave principal, que determina en quÃ© nodo se almacenan los datos. Las rÃ©plicas son copias de filas. Cuando los datos se escriben por primera vez, tambiÃ©n se los denomina rÃ©plica.
>
>Los factores que influyen en la replicaciÃ³n incluyen:
>
>Nodos virtuales : asigna la propiedad de los datos a las mÃ¡quinas fÃ­sicas.
>Particionador : divide los datos en el clÃºster.
>Estrategia de replicaciÃ³n : determina las rÃ©plicas para cada fila de datos.
>Snitch : define la informaciÃ³n de topologÃ­a que utiliza la estrategia de replicaciÃ³n para colocar rÃ©plicas.
>
>Entonces... Cassandra admite sharding?
>
>Si, Cassandra admite la fragmentaciÃ³n horizontal, pero de una forma no tradicional.
>
>En Mongodb, cada nodo secundario contiene datos completos del nodo principal, pero en Cassandra, cada nodo secundario tiene la responsabilidad de mantener solo algunas particiones clave de datos.
>
>Cassandra divide los nodos (porque si no puede dividirlo, no puede escalarlo). Todos los datos de un clÃºster de Cassandra se dividen en "el anillo" y cada nodo del anillo es responsable de uno o mÃ¡s rangos de claves. Se tiene control sobre el particionador (p. ej., aleatorio, ordenado) y sobre cuÃ¡ntos nodos en el anillo se debe replicar una clave/columna segÃºn sus requisitos.
>
>Entonces... es una buena soluciÃ³n para el problema el usar cassandra?
>
>SegÃºn Nuestro Juicio si es una buena soluciÃ³n, al igual que Fruitter, al pertenecer a Melon Musk es un producto que si o si crecerÃ¡ de manera exponencial en su inicio de producciÃ³n, entonces estarÃ¡ evolucionando rÃ¡pidamente y estÃ¡ en "modo de inicio", Cassandra podrÃ­a ser una buena opciÃ³n debido a su modelo de datos sin esquema. Esto facilita mantener la base de datos al dÃ­a con los cambios de la aplicaciÃ³n a medida que se implementa rÃ¡pidamente.
>
>Por otro lado, hay que mirar la distribuciÃ³n geogrÃ¡fica, Cassandra tiene soporte listo para usar para la distribuciÃ³n geogrÃ¡fica de datos. Se puede configurar Cassandra fÃ¡cilmente para replicar datos en mÃºltiples centros de datos. Esto ya que La nueva aplicaciÃ³n implementada es algo de caracter global, que podrÃ­a ver un beneficio de rendimiento al poner los datos cerca del usuario.
>
>Para fragmentar, se necesita encontrar una buena clave para ordenar sus registros. Por ejemplo, se podrÃ­a dividir los registros de los clientes en 26 mÃ¡quinas, una para cada letra del alfabeto, cada una de las cuales alojarÃ­a solo los registros de los clientes cuyos apellidos comienzan con esa letra en particular. Sin embargo, es probable que esta no sea una buena estrategia por la carga que recibirÃ­an las letras mÃ¡s usadas vs las menos usadas.
>
>Entonces una propuesta es fragmentar de acuerdo con algo numÃ©rico, como el rut de las personas o el id de las entidades(recetas o clientes), aunque todo depende de cÃ³mo es probable que se distribuyan los datos especÃ­ficos.
>
>
